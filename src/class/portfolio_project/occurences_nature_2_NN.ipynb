{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIVARIATE NONLINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot\n",
    "import seaborn\n",
    "import itertools\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, r2_score\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUGGING ANNOYING WARNING\n",
    "# tensorflow.debugging.set_log_device_placement(True)\n",
    "from tensorflow.python.data.util import options as options_lib\n",
    "from tensorflow.python.data.experimental import DistributeOptions, AutoShardPolicy\n",
    "\n",
    "DistributeOptions.auto_shard_policy = options_lib.create_option(\n",
    "    name=\"auto_shard_policy\",\n",
    "    ty=AutoShardPolicy,\n",
    "    docstring=\"The type of sharding to use. See \"\n",
    "    \"`tf.data.experimental.AutoShardPolicy` for additional information.\",\n",
    "    default_factory=lambda: AutoShardPolicy.DATA,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT PARAMETERS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/higoreller/miniconda3/envs/condaenv/lib/python3.9/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Cell F221384 is marked as a date but the serial value -736954.9663425926 is outside the limits for dates. The cell will be treated as an error.\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naturezas</th>\n",
       "      <th>bairro_cidade</th>\n",
       "      <th>recurso</th>\n",
       "      <th>obm_escala</th>\n",
       "      <th>dia</th>\n",
       "      <th>periodo</th>\n",
       "      <th>tempo_resposta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RESGATE (3)-&gt;EMERGÊNCIA CLÍNICA (304)-&gt;CRISE H...</td>\n",
       "      <td>VILA OLIVEIRA - APARECIDA DE GOIÂNIA</td>\n",
       "      <td>UR-226</td>\n",
       "      <td>7º BBM - APARECIDA DE GOIÂNIA</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>Madrugada</td>\n",
       "      <td>Rápido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BUSCA E SALVAMENTO (4)-&gt;PESSOAS (403)-&gt;RETIRAD...</td>\n",
       "      <td>LUCILENE - SANTA HELENA DE GOIÁS</td>\n",
       "      <td>UR-171</td>\n",
       "      <td>3ª CIBM - SANTA HELENA</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>Madrugada</td>\n",
       "      <td>Rápido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RESGATE (3)-&gt;ACIDENTE DE TRÂNSITO (301)-&gt;CARRO...</td>\n",
       "      <td>SÍTIOS SANTA LUZIA - APARECIDA DE GOIÂNIA</td>\n",
       "      <td>UR-140</td>\n",
       "      <td>7º BBM - APARECIDA DE GOIÂNIA</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>Madrugada</td>\n",
       "      <td>Longo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INCÊNDIO URBANO (6)-&gt;VEÍCULOS (610)-&gt;VEÍCULO D...</td>\n",
       "      <td>ZONA RURAL - NIQUELÂNDIA</td>\n",
       "      <td>ABTS-07</td>\n",
       "      <td>6ª CIBM - NIQUELÂNDIA</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>Madrugada</td>\n",
       "      <td>Muito rápido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RESGATE (3)-&gt;EMERGÊNCIA CLÍNICA (304)-&gt;ACIDENT...</td>\n",
       "      <td>ZONA RURAL - CATALÃO</td>\n",
       "      <td>UR-181</td>\n",
       "      <td>10º BBM - CATALÃO</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>Madrugada</td>\n",
       "      <td>Muito rápido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>RESGATE (3)-&gt;ACIDENTE DE TRÂNSITO (301)-&gt;CAPOT...</td>\n",
       "      <td>ZONA RURAL - ITAUÇU</td>\n",
       "      <td>ASA-77</td>\n",
       "      <td>7ª CIBM - INHUMAS</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>Vespertino</td>\n",
       "      <td>Extremamente longo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>RESGATE (3)-&gt;ACIDENTE DE TRÂNSITO (301)-&gt;CAPOT...</td>\n",
       "      <td>ZONA RURAL - ITAUÇU</td>\n",
       "      <td>UR-189</td>\n",
       "      <td>7ª CIBM - INHUMAS</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>Vespertino</td>\n",
       "      <td>Extremamente longo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>RESGATE (3)-&gt;ACIDENTE DE TRÂNSITO (301)-&gt;CAPOT...</td>\n",
       "      <td>ZONA RURAL - ITAUÇU</td>\n",
       "      <td>UR-189</td>\n",
       "      <td>7ª CIBM - INHUMAS</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>Vespertino</td>\n",
       "      <td>Extremamente longo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>RESGATE (3)-&gt;ACIDENTE DE TRÂNSITO (301)-&gt;CAPOT...</td>\n",
       "      <td>ZONA RURAL - ITAUÇU</td>\n",
       "      <td>UR-200</td>\n",
       "      <td>7ª CIBM - INHUMAS</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>Vespertino</td>\n",
       "      <td>Extremamente longo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>RESGATE (3)-&gt;ACIDENTE DE TRÂNSITO (301)-&gt;CAPOT...</td>\n",
       "      <td>ZONA RURAL - ITAUÇU</td>\n",
       "      <td>UR-200</td>\n",
       "      <td>7ª CIBM - INHUMAS</td>\n",
       "      <td>Domingo</td>\n",
       "      <td>Vespertino</td>\n",
       "      <td>Extremamente longo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             naturezas  \\\n",
       "1    RESGATE (3)->EMERGÊNCIA CLÍNICA (304)->CRISE H...   \n",
       "2    BUSCA E SALVAMENTO (4)->PESSOAS (403)->RETIRAD...   \n",
       "3    RESGATE (3)->ACIDENTE DE TRÂNSITO (301)->CARRO...   \n",
       "4    INCÊNDIO URBANO (6)->VEÍCULOS (610)->VEÍCULO D...   \n",
       "5    RESGATE (3)->EMERGÊNCIA CLÍNICA (304)->ACIDENT...   \n",
       "..                                                 ...   \n",
       "196  RESGATE (3)->ACIDENTE DE TRÂNSITO (301)->CAPOT...   \n",
       "197  RESGATE (3)->ACIDENTE DE TRÂNSITO (301)->CAPOT...   \n",
       "198  RESGATE (3)->ACIDENTE DE TRÂNSITO (301)->CAPOT...   \n",
       "199  RESGATE (3)->ACIDENTE DE TRÂNSITO (301)->CAPOT...   \n",
       "200  RESGATE (3)->ACIDENTE DE TRÂNSITO (301)->CAPOT...   \n",
       "\n",
       "                                 bairro_cidade  recurso  \\\n",
       "1         VILA OLIVEIRA - APARECIDA DE GOIÂNIA   UR-226   \n",
       "2             LUCILENE - SANTA HELENA DE GOIÁS   UR-171   \n",
       "3    SÍTIOS SANTA LUZIA - APARECIDA DE GOIÂNIA   UR-140   \n",
       "4                     ZONA RURAL - NIQUELÂNDIA  ABTS-07   \n",
       "5                         ZONA RURAL - CATALÃO   UR-181   \n",
       "..                                         ...      ...   \n",
       "196                        ZONA RURAL - ITAUÇU   ASA-77   \n",
       "197                        ZONA RURAL - ITAUÇU   UR-189   \n",
       "198                        ZONA RURAL - ITAUÇU   UR-189   \n",
       "199                        ZONA RURAL - ITAUÇU   UR-200   \n",
       "200                        ZONA RURAL - ITAUÇU   UR-200   \n",
       "\n",
       "                        obm_escala      dia     periodo      tempo_resposta  \n",
       "1    7º BBM - APARECIDA DE GOIÂNIA  Domingo   Madrugada              Rápido  \n",
       "2           3ª CIBM - SANTA HELENA  Domingo   Madrugada              Rápido  \n",
       "3    7º BBM - APARECIDA DE GOIÂNIA  Domingo   Madrugada               Longo  \n",
       "4            6ª CIBM - NIQUELÂNDIA  Domingo   Madrugada        Muito rápido  \n",
       "5                10º BBM - CATALÃO  Domingo   Madrugada        Muito rápido  \n",
       "..                             ...      ...         ...                 ...  \n",
       "196              7ª CIBM - INHUMAS  Domingo  Vespertino  Extremamente longo  \n",
       "197              7ª CIBM - INHUMAS  Domingo  Vespertino  Extremamente longo  \n",
       "198              7ª CIBM - INHUMAS  Domingo  Vespertino  Extremamente longo  \n",
       "199              7ª CIBM - INHUMAS  Domingo  Vespertino  Extremamente longo  \n",
       "200              7ª CIBM - INHUMAS  Domingo  Vespertino  Extremamente longo  \n",
       "\n",
       "[169 rows x 7 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA PRE-PREPARATION\n",
    "file_path = '../../../dataset/occurrences.xlsx'\n",
    "\n",
    "df = pandas.read_excel(file_path)\n",
    "df = df.drop([\"rai\", \"obm_afeto\", \"qualificacao\", \"sexo\"], axis=1).loc[0:200,:] \n",
    "\n",
    "#REMOVING NULL VALUES\n",
    "df.loc[pandas.isnull(df[\"data\"])]\n",
    "df.loc[pandas.isnull(df[\"naturezas\"])]\n",
    "df.loc[pandas.isnull(df[\"bairro_cidade\"])]\n",
    "df.loc[pandas.isnull(df[\"tr\"])]\n",
    "df.loc[pandas.isnull(df[\"obm_escala\"])]\n",
    "\n",
    "df = df.loc[df[\"bairro_cidade\"] != \"(null)\"]\n",
    "df = df.loc[df[\"recurso\"] != \"(null)\"]\n",
    "df = df.loc[df[\"tr\"] != \"(null)\"]\n",
    "df = df.loc[df[\"obm_escala\"] != \"(null)\"]\n",
    "\n",
    "#TRANSFORMING \"data\" COLUMN INTO NEW COLUMNS \"dia\" e \"periodo\". ALSO TRANSFORMING \"tr\" COLUMN INTO \"tempo_resposta\" COLUMN\n",
    "\n",
    "def day_name(timestamp):\n",
    "    weekdays = ('Segunda-feira', 'Terça-feira', 'Quarta-feira', 'Quinta-feira', 'Sexta-feira', 'Sábado', 'Domingo')\n",
    "    return weekdays[timestamp.weekday()]\n",
    "\n",
    "def period_of_day(timestamp):\n",
    "    period = (\"Madrugada\", \"Matutino\", \"Vespertino\", \"Noturno\")\n",
    "    # Madrugada 00:00 às 05:59\n",
    "    # Matutino 06:00 às 11:59\n",
    "    # Vespertino 12:00 às 17:59\n",
    "    # Noturno 18:00 às 23:59\n",
    "    if timestamp.hour >= 0 and timestamp.hour < 6:\n",
    "        return period[0]\n",
    "    elif timestamp.hour >= 6 and timestamp.hour < 12:\n",
    "        return period[1]\n",
    "    elif timestamp.hour >= 12 and timestamp.hour < 18:\n",
    "        return period[2]\n",
    "    elif timestamp.hour >= 18 and timestamp.hour < 24:\n",
    "        return period[3]\n",
    "\n",
    "\n",
    "\n",
    "def response_time(response_time):\n",
    "    # Muito rápido 0 a 10 minutos\n",
    "    # Rápido 10 a 15 minutos\n",
    "    # Médio 15 a 20 minutos\n",
    "    # Longo 20 a 30 minutos\n",
    "    # Muito longo 30 a 45 minutos\n",
    "    # Extremamente longo > 45 minutos\n",
    "\n",
    "    response_time_metric = (\"Muito rápido\", \"Rápido\", \"Médio\", \"Longo\", \"Muito longo\", \"Extremamente longo\")\n",
    "\n",
    "    if type(response_time) is datetime.time:\n",
    "\n",
    "        total_time_in_minutes = response_time.hour*60 + response_time.minute + response_time.second/60\n",
    "\n",
    "        if total_time_in_minutes >= 0 and total_time_in_minutes <= 10:\n",
    "            return response_time_metric[0]\n",
    "        elif total_time_in_minutes > 10 and total_time_in_minutes <= 15:\n",
    "            return response_time_metric[1]\n",
    "        elif total_time_in_minutes > 15 and total_time_in_minutes <= 20:\n",
    "            return response_time_metric[2]\n",
    "        elif total_time_in_minutes > 20 and total_time_in_minutes <= 30:\n",
    "            return response_time_metric[3]\n",
    "        elif total_time_in_minutes > 30 and total_time_in_minutes <= 45:\n",
    "            return response_time_metric[4]\n",
    "        elif total_time_in_minutes > 45:\n",
    "            return response_time_metric[5]\n",
    "        \n",
    "#Lembrar de remover os valores que não são datetime.time do df[\"tr\"]\n",
    "df.loc[:, \"dia\"] = df[\"data\"].apply(day_name)\n",
    "df.loc[:, \"periodo\"] = df[\"data\"].apply(period_of_day)\n",
    "df.loc[:, \"tempo_resposta\"] = df[\"tr\"].apply(response_time)\n",
    "\n",
    "#REMOVING \"DATA\" AND \"TR\" COLUMNS\n",
    "\n",
    "df = df.drop([\"data\", \"tr\"], axis=1)\n",
    "\n",
    "#Removing None values\n",
    "df = df.dropna()\n",
    "df = df.mask(df.eq('None')).dropna()\n",
    "df = df.astype(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PARAMETERS\n",
    "\n",
    "var_types = {'naturezas' : 'str',\n",
    "             'bairro_cidade' : 'str',\n",
    "             'recurso' : 'str',\n",
    "             'dia': 'str',\n",
    "             'periodo': 'str',\n",
    "             'tempo_resposta': 'str',\n",
    "             'obm_escala': 'str',\n",
    "             }\n",
    "\n",
    "# COOK PARAMETERS\n",
    "reg_col = 'tempo_resposta'\n",
    "folding_sampler = 'tempo_resposta'\n",
    "my_metric = 'mse'\n",
    "relevant_features = 4\n",
    "my_patience = 50\n",
    "min_improvement = 0.01\n",
    "min_neuron_gain = 0.025\n",
    "random_seed = 42\n",
    "n_k_folds = 5\n",
    "learning_rate = 0.01\n",
    "hidden_activations = ['linear', 'sigmoid']\n",
    "print_anyway = True\n",
    "rollback_on_no_bound_gain = True\n",
    "my_optimizers = ['adam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT AND CONVERT\n",
    "for input_col in var_types.keys():\n",
    "    df[input_col] = df[input_col].astype(var_types[input_col])\n",
    "\n",
    "# SCATTER PLOT\n",
    "#g = seaborn.pairplot(df, hue='naturezas', height=3, diag_kind='kde')\n",
    "#_ = g.map_lower(seaborn.kdeplot, levels=1, color=\".2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROBUST COOKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">X</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">categorical</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">categorical</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>10ª CIBM - POSSE</th>\n",
       "      <th>10º BBM - CATALÃO</th>\n",
       "      <th>11ª CIBM - URUAÇU</th>\n",
       "      <th>11º BBM - PORANGATU</th>\n",
       "      <th>12ª CIBM - MORRINHOS</th>\n",
       "      <th>12º BBM - GOIÁS</th>\n",
       "      <th>13º BBM - JATAÍ</th>\n",
       "      <th>14ª CIBM - PIRES DO RIO</th>\n",
       "      <th>14º BBM - SENADOR CANEDO</th>\n",
       "      <th>15ª CIBM - QUIRINÓPOLIS</th>\n",
       "      <th>...</th>\n",
       "      <th>RESGATE (3)-&gt;EMERGÊNCIA CLÍNICA (304)-&gt;OUTRO / EMERGÊNCIA CLÍNICA (30499)</th>\n",
       "      <th>RESGATE (3)-&gt;EMERGÊNCIA CLÍNICA (304)-&gt;PARADA CARDIORRESPIRATÓRIA (30408)</th>\n",
       "      <th>RESGATE (3)-&gt;EMERGÊNCIA CLÍNICA (304)-&gt;PROBLEMAS CARDÍACOS (30409)</th>\n",
       "      <th>RESGATE (3)-&gt;EMERGÊNCIA CLÍNICA (304)-&gt;PROBLEMAS NO SISTEMA DIGESTIVO (30411)</th>\n",
       "      <th>RESGATE (3)-&gt;EMERGÊNCIA CLÍNICA (304)-&gt;PROBLEMAS NO SISTEMA URINÁRIO (30412)</th>\n",
       "      <th>RESGATE (3)-&gt;INTOXICAÇÃO EXÓGENA (306)-&gt;ALCOOL (30602)</th>\n",
       "      <th>RESGATE (3)-&gt;INTOXICAÇÃO EXÓGENA (306)-&gt;MEDICAMENTOS (30605)</th>\n",
       "      <th>RESGATE (3)-&gt;QUEDA DE ALTURA (308)-&gt;DA PRÓPRIA ALTURA (30801)</th>\n",
       "      <th>RESGATE (3)-&gt;TENTATIVA DE AUTO-EXTERMÍNIO (309)-&gt;POR ARMA BRANCA (30904)</th>\n",
       "      <th>RESGATE (3)-&gt;TRANSPORTE (310)-&gt;INTRA HOSPITALAR (MILITAR) (31006)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   X                                                          \\\n",
       "         categorical                                                           \n",
       "    10ª CIBM - POSSE 10º BBM - CATALÃO 11ª CIBM - URUAÇU 11º BBM - PORANGATU   \n",
       "1                0.0               0.0               0.0                 0.0   \n",
       "2                0.0               0.0               0.0                 0.0   \n",
       "3                0.0               0.0               0.0                 0.0   \n",
       "4                0.0               0.0               0.0                 0.0   \n",
       "5                0.0               1.0               0.0                 0.0   \n",
       "..               ...               ...               ...                 ...   \n",
       "196              0.0               0.0               0.0                 0.0   \n",
       "197              0.0               0.0               0.0                 0.0   \n",
       "198              0.0               0.0               0.0                 0.0   \n",
       "199              0.0               0.0               0.0                 0.0   \n",
       "200              0.0               0.0               0.0                 0.0   \n",
       "\n",
       "                                                          \\\n",
       "                                                           \n",
       "    12ª CIBM - MORRINHOS 12º BBM - GOIÁS 13º BBM - JATAÍ   \n",
       "1                    0.0             0.0             0.0   \n",
       "2                    0.0             0.0             0.0   \n",
       "3                    0.0             0.0             0.0   \n",
       "4                    0.0             0.0             0.0   \n",
       "5                    0.0             0.0             0.0   \n",
       "..                   ...             ...             ...   \n",
       "196                  0.0             0.0             0.0   \n",
       "197                  0.0             0.0             0.0   \n",
       "198                  0.0             0.0             0.0   \n",
       "199                  0.0             0.0             0.0   \n",
       "200                  0.0             0.0             0.0   \n",
       "\n",
       "                                                                              \\\n",
       "                                                                               \n",
       "    14ª CIBM - PIRES DO RIO 14º BBM - SENADOR CANEDO 15ª CIBM - QUIRINÓPOLIS   \n",
       "1                       0.0                      0.0                     0.0   \n",
       "2                       0.0                      0.0                     0.0   \n",
       "3                       0.0                      0.0                     0.0   \n",
       "4                       0.0                      0.0                     0.0   \n",
       "5                       0.0                      0.0                     0.0   \n",
       "..                      ...                      ...                     ...   \n",
       "196                     0.0                      0.0                     0.0   \n",
       "197                     0.0                      0.0                     0.0   \n",
       "198                     0.0                      0.0                     0.0   \n",
       "199                     0.0                      0.0                     0.0   \n",
       "200                     0.0                      0.0                     0.0   \n",
       "\n",
       "     ...  \\\n",
       "     ...   \n",
       "     ...   \n",
       "1    ...   \n",
       "2    ...   \n",
       "3    ...   \n",
       "4    ...   \n",
       "5    ...   \n",
       "..   ...   \n",
       "196  ...   \n",
       "197  ...   \n",
       "198  ...   \n",
       "199  ...   \n",
       "200  ...   \n",
       "\n",
       "                                                                            Y  \\\n",
       "                                                                  categorical   \n",
       "    RESGATE (3)->EMERGÊNCIA CLÍNICA (304)->OUTRO / EMERGÊNCIA CLÍNICA (30499)   \n",
       "1                                                  0.0                          \n",
       "2                                                  0.0                          \n",
       "3                                                  0.0                          \n",
       "4                                                  0.0                          \n",
       "5                                                  0.0                          \n",
       "..                                                 ...                          \n",
       "196                                                0.0                          \n",
       "197                                                0.0                          \n",
       "198                                                0.0                          \n",
       "199                                                0.0                          \n",
       "200                                                0.0                          \n",
       "\n",
       "                                                                               \\\n",
       "                                                                                \n",
       "    RESGATE (3)->EMERGÊNCIA CLÍNICA (304)->PARADA CARDIORRESPIRATÓRIA (30408)   \n",
       "1                                                  0.0                          \n",
       "2                                                  0.0                          \n",
       "3                                                  0.0                          \n",
       "4                                                  0.0                          \n",
       "5                                                  0.0                          \n",
       "..                                                 ...                          \n",
       "196                                                0.0                          \n",
       "197                                                0.0                          \n",
       "198                                                0.0                          \n",
       "199                                                0.0                          \n",
       "200                                                0.0                          \n",
       "\n",
       "                                                                        \\\n",
       "                                                                         \n",
       "    RESGATE (3)->EMERGÊNCIA CLÍNICA (304)->PROBLEMAS CARDÍACOS (30409)   \n",
       "1                                                  0.0                   \n",
       "2                                                  0.0                   \n",
       "3                                                  0.0                   \n",
       "4                                                  0.0                   \n",
       "5                                                  0.0                   \n",
       "..                                                 ...                   \n",
       "196                                                0.0                   \n",
       "197                                                0.0                   \n",
       "198                                                0.0                   \n",
       "199                                                0.0                   \n",
       "200                                                0.0                   \n",
       "\n",
       "                                                                                   \\\n",
       "                                                                                    \n",
       "    RESGATE (3)->EMERGÊNCIA CLÍNICA (304)->PROBLEMAS NO SISTEMA DIGESTIVO (30411)   \n",
       "1                                                  0.0                              \n",
       "2                                                  0.0                              \n",
       "3                                                  0.0                              \n",
       "4                                                  0.0                              \n",
       "5                                                  0.0                              \n",
       "..                                                 ...                              \n",
       "196                                                0.0                              \n",
       "197                                                0.0                              \n",
       "198                                                0.0                              \n",
       "199                                                0.0                              \n",
       "200                                                0.0                              \n",
       "\n",
       "                                                                                  \\\n",
       "                                                                                   \n",
       "    RESGATE (3)->EMERGÊNCIA CLÍNICA (304)->PROBLEMAS NO SISTEMA URINÁRIO (30412)   \n",
       "1                                                  0.0                             \n",
       "2                                                  0.0                             \n",
       "3                                                  0.0                             \n",
       "4                                                  0.0                             \n",
       "5                                                  0.0                             \n",
       "..                                                 ...                             \n",
       "196                                                0.0                             \n",
       "197                                                0.0                             \n",
       "198                                                0.0                             \n",
       "199                                                0.0                             \n",
       "200                                                0.0                             \n",
       "\n",
       "                                                            \\\n",
       "                                                             \n",
       "    RESGATE (3)->INTOXICAÇÃO EXÓGENA (306)->ALCOOL (30602)   \n",
       "1                                                  0.0       \n",
       "2                                                  0.0       \n",
       "3                                                  0.0       \n",
       "4                                                  0.0       \n",
       "5                                                  0.0       \n",
       "..                                                 ...       \n",
       "196                                                0.0       \n",
       "197                                                0.0       \n",
       "198                                                0.0       \n",
       "199                                                0.0       \n",
       "200                                                0.0       \n",
       "\n",
       "                                                                  \\\n",
       "                                                                   \n",
       "    RESGATE (3)->INTOXICAÇÃO EXÓGENA (306)->MEDICAMENTOS (30605)   \n",
       "1                                                  0.0             \n",
       "2                                                  0.0             \n",
       "3                                                  0.0             \n",
       "4                                                  0.0             \n",
       "5                                                  0.0             \n",
       "..                                                 ...             \n",
       "196                                                0.0             \n",
       "197                                                0.0             \n",
       "198                                                0.0             \n",
       "199                                                0.0             \n",
       "200                                                0.0             \n",
       "\n",
       "                                                                   \\\n",
       "                                                                    \n",
       "    RESGATE (3)->QUEDA DE ALTURA (308)->DA PRÓPRIA ALTURA (30801)   \n",
       "1                                                  0.0              \n",
       "2                                                  0.0              \n",
       "3                                                  0.0              \n",
       "4                                                  0.0              \n",
       "5                                                  0.0              \n",
       "..                                                 ...              \n",
       "196                                                0.0              \n",
       "197                                                0.0              \n",
       "198                                                0.0              \n",
       "199                                                0.0              \n",
       "200                                                0.0              \n",
       "\n",
       "                                                                              \\\n",
       "                                                                               \n",
       "    RESGATE (3)->TENTATIVA DE AUTO-EXTERMÍNIO (309)->POR ARMA BRANCA (30904)   \n",
       "1                                                  0.0                         \n",
       "2                                                  0.0                         \n",
       "3                                                  0.0                         \n",
       "4                                                  0.0                         \n",
       "5                                                  0.0                         \n",
       "..                                                 ...                         \n",
       "196                                                0.0                         \n",
       "197                                                0.0                         \n",
       "198                                                0.0                         \n",
       "199                                                0.0                         \n",
       "200                                                0.0                         \n",
       "\n",
       "                                                                       \n",
       "                                                                       \n",
       "    RESGATE (3)->TRANSPORTE (310)->INTRA HOSPITALAR (MILITAR) (31006)  \n",
       "1                                                  0.0                 \n",
       "2                                                  0.0                 \n",
       "3                                                  0.0                 \n",
       "4                                                  0.0                 \n",
       "5                                                  0.0                 \n",
       "..                                                 ...                 \n",
       "196                                                0.0                 \n",
       "197                                                0.0                 \n",
       "198                                                0.0                 \n",
       "199                                                0.0                 \n",
       "200                                                0.0                 \n",
       "\n",
       "[169 rows x 290 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SET THE RANDOM SEED\n",
    "numpy.random.seed(random_seed)\n",
    "tensorflow.random.set_seed(random_seed)\n",
    "\n",
    "# QUANTIFY REPRESENTATION \n",
    "dfn_mi_list = []\n",
    "dfn_data_list = []\n",
    "for my_var in var_types.keys():\n",
    "    if my_var == reg_col:\n",
    "        col_class = 'Y'\n",
    "    else:\n",
    "        col_class = 'X'\n",
    "\n",
    "    if var_types[my_var] == 'float': # NUMERIC DATA\n",
    "        dfn_mi_list.append((col_class, 'continuous', my_var))\n",
    "        dfn_data_list.append(df[[my_var]].values)\n",
    "\n",
    "    elif var_types[my_var] == 'str': # CATEGORICAL DATA\n",
    "        one_hot = OneHotEncoder(sparse=False)\n",
    "        var_cat = df[[my_var]].to_numpy()\n",
    "        one_hot.fit(var_cat)\n",
    "        cat_df = pandas.DataFrame(one_hot.transform(var_cat))\n",
    "        cat_df.columns = one_hot.categories_\n",
    "        for cat in cat_df.columns:\n",
    "            dfn_mi_list.append((col_class, 'categorical', cat[0]))\n",
    "            dfn_data_list.append(cat_df[[cat]].values)\n",
    "\n",
    "dfn_mi = pandas.MultiIndex.from_tuples(dfn_mi_list)\n",
    "dfn = pandas.DataFrame(index=df.index, columns=dfn_mi, data=numpy.concatenate(dfn_data_list, axis=1))\n",
    "dfn = dfn.sort_index(axis=1)\n",
    "dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "# NUMPY MATRIX FOR TRAINING\n",
    "X = dfn['X'].to_numpy()\n",
    "my_vars = list(dfn['X'].columns.get_level_values(1))\n",
    "Y = dfn['Y'].to_numpy()\n",
    "\n",
    "# NORMALIZE VARIABLES\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler = X_scaler.fit(X)\n",
    "X_scaled = X_scaler.transform(X)\n",
    "\n",
    "# TRANSFORM Y\n",
    "Y_scaler = None\n",
    "if var_types[reg_col] == 'float': # IF REGRESSION NORMALIZE\n",
    "    Y_scaler = StandardScaler()\n",
    "    Y_scaler = Y_scaler.fit(Y)\n",
    "    Y_scaled = Y_scaler.transform(Y)\n",
    "else:\n",
    "    Y_scaled = Y\n",
    "\n",
    "# Y SAMPLING\n",
    "Y_sample = df[[folding_sampler]].to_numpy()\n",
    "\n",
    "# GET STRATIFIED FOLDS\n",
    "sk_folds = StratifiedKFold(n_splits=n_k_folds)\n",
    "sk_folds.get_n_splits(X_scaled, Y_sample)\n",
    "\n",
    "# TRAINING LOOP\n",
    "n_classes = dfn['Y'].columns.shape[0]\n",
    "hidden_layers = 1\n",
    "\n",
    "# PATTERN SEARCH\n",
    "search_vector = numpy.identity(len(hidden_activations), dtype=int)\n",
    "current_configurations = search_vector\n",
    "\n",
    "still_searching = True\n",
    "best_net_name = None\n",
    "best_net = None\n",
    "best_config = None\n",
    "\n",
    "if my_metric == 'mse':\n",
    "    my_mode = 'min'\n",
    "    best_metric = 1.0\n",
    "    best_metric_val = 1.0\n",
    "    metric_bound = 1000.0\n",
    "else:\n",
    "    my_mode = 'max'\n",
    "    best_metric = 0.0\n",
    "    best_metric_val = 0.0\n",
    "    metric_bound = 0.0\n",
    "\n",
    "\n",
    "result_list = []\n",
    "\n",
    "# RUNNING ON GPU AND CPU\n",
    "strategy = tensorflow.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COOKING BEST NETWORK STARTED...\n",
      "\n",
      "CONFIG: [1 0]\n",
      "FOLD: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/higoreller/miniconda3/envs/condaenv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "2022-08-17 15:16:21.465254: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:16:51.472606: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR1_ADAM_F1_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 75 loss: 0.96 val_loss: 1.07 mse: 0.96 val_mse: 1.07 \n",
      "FOLD: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 15:17:23.420754: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:17:53.471703: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR1_ADAM_F2_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 71 loss: 0.96 val_loss: 1.10 mse: 0.96 val_mse: 1.10 \n",
      "FOLD: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 15:18:26.094316: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:18:56.100805: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR1_ADAM_F3_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 68 loss: 0.96 val_loss: 1.10 mse: 0.96 val_mse: 1.10 \n",
      "FOLD: 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 15:19:26.263451: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:19:56.273735: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR1_ADAM_F4_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 62 loss: 1.01 val_loss: 0.91 mse: 1.01 val_mse: 0.91 \n",
      "FOLD: 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 15:20:28.869336: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:20:58.887483: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR1_ADAM_F5_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 62 loss: 1.00 val_loss: 0.95 mse: 1.00 val_mse: 0.95 **Best NET!**\n",
      "CONFIG: [0 1]\n",
      "FOLD: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/higoreller/miniconda3/envs/condaenv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "2022-08-17 15:21:28.966873: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:21:59.117969: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:22:29.213123: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIGMOID1_ADAM_F1_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 55 loss: 0.98 val_loss: 1.07 mse: 0.98 val_mse: 1.07 \n",
      "FOLD: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 15:22:59.435501: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:23:29.527852: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIGMOID1_ADAM_F2_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 52 loss: 0.97 val_loss: 1.08 mse: 0.97 val_mse: 1.08 \n",
      "FOLD: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 15:23:59.644657: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:24:29.761004: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:24:59.808435: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIGMOID1_ADAM_F3_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 54 loss: 0.98 val_loss: 1.06 mse: 0.98 val_mse: 1.06 \n",
      "FOLD: 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 15:25:29.887526: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:25:59.894701: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIGMOID1_ADAM_F4_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 54 loss: 1.02 val_loss: 0.89 mse: 1.02 val_mse: 0.89 \n",
      "FOLD: 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 15:26:30.291579: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:27:00.366683: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:27:30.556178: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIGMOID1_ADAM_F5_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 57 loss: 1.00 val_loss: 0.95 mse: 1.00 val_mse: 0.95 \n",
      "BEST CONFIG [1 0] & best quality for ADAM: 1.10\n",
      "CONFIG: [2 0]\n",
      "FOLD: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/higoreller/miniconda3/envs/condaenv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "2022-08-17 15:28:06.587574: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:28:36.601579: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR2_ADAM_F1_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 97 loss: 0.94 val_loss: 1.06 mse: 0.94 val_mse: 1.06 \n",
      "FOLD: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 15:29:06.642121: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR2_ADAM_F2_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 68 loss: 0.95 val_loss: 1.11 mse: 0.95 val_mse: 1.11 \n",
      "FOLD: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 15:29:36.721058: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:30:06.792048: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR2_ADAM_F3_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 69 loss: 0.94 val_loss: 1.17 mse: 0.94 val_mse: 1.17 \n",
      "FOLD: 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 15:30:40.109476: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:31:10.264145: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR2_ADAM_F4_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 70 loss: 1.00 val_loss: 1.11 mse: 1.00 val_mse: 1.11 \n",
      "FOLD: 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 15:31:42.221096: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:32:12.329454: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR2_ADAM_F5_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 65 loss: 0.98 val_loss: 0.95 mse: 0.98 val_mse: 0.95 \n",
      "CONFIG: [1 1]\n",
      "FOLD: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/higoreller/miniconda3/envs/condaenv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "2022-08-17 15:32:44.958455: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:33:15.028038: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR1SIGMOID1_ADAM_F1_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 61 loss: 0.96 val_loss: 1.08 mse: 0.96 val_mse: 1.08 \n",
      "FOLD: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 15:33:45.158142: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:34:15.284511: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:34:45.307394: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR1SIGMOID1_ADAM_F2_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 85 loss: 0.95 val_loss: 1.10 mse: 0.95 val_mse: 1.10 \n",
      "FOLD: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 15:35:15.348071: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:35:45.554678: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:36:15.693919: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR1SIGMOID1_ADAM_F3_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 87 loss: 0.95 val_loss: 1.09 mse: 0.95 val_mse: 1.09 \n",
      "FOLD: 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 15:36:45.742800: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:37:15.745827: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:37:46.450752: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR1SIGMOID1_ADAM_F4_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 74 loss: 1.00 val_loss: 0.91 mse: 1.00 val_mse: 0.91 \n",
      "FOLD: 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 15:38:16.501169: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:38:46.518129: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-17 15:39:17.583821: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR1SIGMOID1_ADAM_F5_10ª CIBM - POSSE_10º BBM - CATALÃO_11ª CIBM - URUAÇU_11º BBM - PORANGATU > epochs: 78 loss: 0.99 val_loss: 0.95 mse: 0.99 val_mse: 0.95 \n",
      "NETs w 2 neurons didnt improve mse!\n"
     ]
    }
   ],
   "source": [
    "print('COOKING BEST NETWORK STARTED...\\n')\n",
    "while still_searching:\n",
    "    for net_config in current_configurations:\n",
    "        print('CONFIG: {}'.format(net_config))\n",
    "        ix_fold = 1\n",
    "        for train_index, test_index in sk_folds.split(X_scaled, Y_sample):\n",
    "            print('FOLD: {}/{}'.format(ix_fold, n_k_folds))\n",
    "\n",
    "            # GET STRATIFIED DATA\n",
    "            X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "            Y_train, Y_test = Y_scaled[train_index], Y_scaled[test_index]\n",
    "            for optimizer in my_optimizers:\n",
    "\n",
    "                # Open a strategy scope and create/restore the model\n",
    "                with strategy.scope():\n",
    "                    # DECLARE OPTIMIZERS INSIDE SCOPE\n",
    "                    _optimizers = {'adagrad': tensorflow.keras.optimizers.Adagrad(learning_rate=learning_rate),\n",
    "                                   'rmsprop': tensorflow.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "                                   'adam': tensorflow.keras.optimizers.Adam(learning_rate=learning_rate)}\n",
    "                    # DECLARE NET\n",
    "                    inputs = keras.Input(shape=(X_train.shape[1], ))\n",
    "                    hidden_layer_list = []\n",
    "                    net_name = ''\n",
    "                    for ix_activation in numpy.arange(len(net_config)):\n",
    "                        f_activation = hidden_activations[ix_activation]\n",
    "                        n_neuron = net_config[ix_activation]\n",
    "                        if n_neuron > 0:\n",
    "                            temp_hidden_layer = keras.layers.Dense(n_neuron, activation=f_activation)(inputs)\n",
    "                            hidden_layer_list.append(temp_hidden_layer)\n",
    "                            net_name += '{}{}'.format(f_activation, n_neuron)\n",
    "                    if len(hidden_layer_list) > 1:\n",
    "                        hidden = keras.layers.Concatenate(axis=1)(hidden_layer_list)\n",
    "                    else:\n",
    "                        hidden = hidden_layer_list[0]\n",
    "                    outputs = keras.layers.Dense(n_classes, activation='linear')(hidden)\n",
    "                    model_name = '{}_{}_F{}_WRAPPER'.format(net_name.upper(), optimizer.upper(), ix_fold)\n",
    "                    my_net = keras.Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "\n",
    "                # COMPILE NET\n",
    "                metric_name = my_metric.lower()\n",
    "                val_metric_name = 'val_{}'.format(metric_name)\n",
    "                my_net.compile(optimizer=_optimizers[optimizer], loss='mse', metrics=[my_metric])\n",
    "                es_loss = tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', patience=my_patience, restore_best_weights=True)\n",
    "                es_metric = tensorflow.keras.callbacks.EarlyStopping(monitor=metric_name, mode=my_mode, patience=my_patience, min_delta=min_improvement)\n",
    "                es_val_metric = tensorflow.keras.callbacks.EarlyStopping(monitor=val_metric_name, mode=my_mode,\n",
    "                                                                         patience=n_k_folds*my_patience, min_delta=min_improvement)\n",
    "\n",
    "                # FIT WRAPPER\n",
    "                history = my_net.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=X_train.shape[0],\n",
    "                                    epochs=10*my_patience, verbose=0, callbacks=[es_loss, es_metric, es_val_metric])\n",
    "\n",
    "                # CALCULATE VARIABLE RELEVANCE\n",
    "                Y_est = my_net.predict(X_scaled, verbose=0)\n",
    "                relevance_dict = {}\n",
    "                for feature in my_vars:\n",
    "                    X_relevance = numpy.copy(X_scaled)\n",
    "                    X_relevance[:, my_vars == feature] = 0.0\n",
    "                    Y_est_relevance = my_net.predict(X_relevance, verbose=0)\n",
    "                    Y_relevance = (Y_est - Y_est_relevance)**2\n",
    "                    feature_relevance = Y_relevance.sum()/Y_relevance.shape[0]\n",
    "                    relevance_dict[feature] = feature_relevance\n",
    "                s_relevance = pandas.Series(relevance_dict)\n",
    "                s_relevance_norm = s_relevance/s_relevance.max()\n",
    "                s_relevance_norm = s_relevance_norm.sort_values(ascending=False).head(relevant_features)\n",
    "                selected_features = list(s_relevance_norm.index.values)\n",
    "                selected_relevance = list(100.0*s_relevance_norm.values)\n",
    "\n",
    "                # FINAL NET\n",
    "                with strategy.scope():\n",
    "                    inputs = keras.Input(shape=(len(selected_features), ))\n",
    "                    hidden_layer_list = []\n",
    "                    net_name = ''\n",
    "                    for ix_activation in numpy.arange(len(net_config)):\n",
    "                        f_activation = hidden_activations[ix_activation]\n",
    "                        n_neuron = net_config[ix_activation]\n",
    "                        if n_neuron > 0:\n",
    "                            temp_hidden_layer = keras.layers.Dense(n_neuron, activation=f_activation)(inputs)\n",
    "                            hidden_layer_list.append(temp_hidden_layer)\n",
    "                            net_name += '{}{}'.format(f_activation, n_neuron)\n",
    "                    if len(hidden_layer_list) > 1:\n",
    "                        hidden = keras.layers.Concatenate(axis=1)(hidden_layer_list)\n",
    "                    else:\n",
    "                        hidden = hidden_layer_list[0]\n",
    "                    outputs = keras.layers.Dense(n_classes, activation='linear')(hidden)\n",
    "                    model_name = '{}_{}_F{}'.format(net_name.upper(), optimizer.upper(), ix_fold)\n",
    "                    my_net = keras.Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "\n",
    "                # COMPILE NET\n",
    "                metric_name = my_metric.lower()\n",
    "                val_metric_name = 'val_{}'.format(metric_name)\n",
    "                my_net.compile(optimizer=_optimizers[optimizer], loss='mse', metrics=[my_metric])\n",
    "                es_loss = tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', patience=my_patience, restore_best_weights=True)\n",
    "                es_metric = tensorflow.keras.callbacks.EarlyStopping(monitor=metric_name, mode=my_mode, patience=my_patience, min_delta=min_improvement)\n",
    "                es_val_metric = tensorflow.keras.callbacks.EarlyStopping(monitor=val_metric_name, mode=my_mode,\n",
    "                                                                        patience=n_k_folds*my_patience, min_delta=min_improvement)\n",
    "\n",
    "                # FIT WRAPPER\n",
    "                ix_relevant = dfn['X'].columns.get_level_values(1).isin(selected_features)\n",
    "                history = my_net.fit(X_train[:, ix_relevant], Y_train, validation_data=(X_test[:, ix_relevant], Y_test), batch_size=X_train.shape[0],\n",
    "                                    epochs=10*my_patience, verbose=0, callbacks=[es_loss, es_metric, es_val_metric])\n",
    "\n",
    "                # UNPACK TRAINING RESULTS\n",
    "                model_loss = history.history['loss'][-1]\n",
    "                model_val_loss = history.history['val_loss'][-1]\n",
    "                metric_val = history.history[metric_name][-1]\n",
    "                val_metric_val = history.history[val_metric_name][-1]\n",
    "                n_epochs = len(history.history['val_loss'])\n",
    "\n",
    "                # CHECK IF BEST NET\n",
    "                best_net_txt = ''\n",
    "                is_best = False\n",
    "                if my_mode == 'max':\n",
    "                    is_best = ((metric_val > best_metric + min_improvement) & (val_metric_val >= best_metric_val)) | ((metric_val >= best_metric) & (val_metric_val > best_metric_val + min_improvement))\n",
    "                elif my_mode == 'min':\n",
    "                    is_best = ((metric_val < best_metric - min_improvement) & (val_metric_val <= best_metric_val)) | ((metric_val <= best_metric) & (val_metric_val < best_metric_val - min_improvement))\n",
    "\n",
    "                if is_best:\n",
    "                    best_net_name = model_name\n",
    "                    best_optimizer = optimizer\n",
    "                    best_config = net_config\n",
    "                    best_features = selected_features\n",
    "                    best_relevance = selected_relevance\n",
    "                    best_net = my_net\n",
    "                    best_neurons = net_config.sum()\n",
    "                    best_metric = metric_val\n",
    "                    best_metric_val = val_metric_val\n",
    "                    best_net_txt = '**Best NET!**'\n",
    "\n",
    "                result_dict = {'model_name': model_name, 'optimizer': optimizer, 'net_config': net_config, 'neurons': net_config.sum(), 'fold': ix_fold, 'features': selected_features, 'relevance': selected_relevance, 'loss': model_loss,\n",
    "                    'val_loss': model_val_loss, metric_name: metric_val, val_metric_name: val_metric_val, 'epochs': n_epochs, 'is_best': is_best, 'net': my_net}\n",
    "                result_list.append(result_dict)\n",
    "                if is_best or print_anyway:\n",
    "                    print('{}_{} > epochs: {} loss: {:.2f} val_loss: {:.2f} {}: {:.2f} {}: {:.2f} {}'.format(model_name,'_'.join(selected_features), n_epochs, model_loss, model_val_loss, metric_name, metric_val, val_metric_name, val_metric_val, best_net_txt))\n",
    "\n",
    "                # IF MAXIMIZED METRICS BREAK\n",
    "                if my_mode == 'max':\n",
    "                    maximized_metrics = (val_metric_val == 1.0) & (metric_val == 1.0)\n",
    "                elif my_mode == 'min':\n",
    "                    maximized_metrics = (val_metric_val == 0.0) & (metric_val == 0.0)\n",
    "\n",
    "                if maximized_metrics:\n",
    "                    break\n",
    "            \n",
    "            if maximized_metrics:\n",
    "                break\n",
    "\n",
    "            ix_fold += 1\n",
    "\n",
    "        if maximized_metrics:\n",
    "            break\n",
    "\n",
    "    # TEST IF MORE NEURONS ARE NECESSARY\n",
    "    dont_need_extra_neurons = False\n",
    "    total_neurons = net_config.sum()\n",
    "\n",
    "    if total_neurons > 1:\n",
    "        \n",
    "        # INCREASING NEURONS DIDNT ACHIEVE BEST NET\n",
    "        if best_neurons < total_neurons:\n",
    "            dont_need_extra_neurons = True\n",
    "            print('NETs w {} neurons didnt improve {}!'.format(total_neurons, metric_name))\n",
    "            break\n",
    "    \n",
    "    # CALCULATE CONFIG BOUND\n",
    "    df_results = pandas.DataFrame(result_list)\n",
    "    ix_config = numpy.array([numpy.linalg.norm(best_config - x) for x in df_results.net_config]) == 0.0\n",
    "    if my_mode == 'max':\n",
    "        bound_est = df_results[(df_results.optimizer == best_optimizer) & ix_config][val_metric_name].min()\n",
    "    elif my_mode == 'min':\n",
    "        bound_est = df_results[(df_results.optimizer == best_optimizer) & ix_config][val_metric_name].max()\n",
    "\n",
    "    # TEST IF LOWER BOUND IMPROVED\n",
    "    bound_didnt_improve = False\n",
    "    if total_neurons > 1:\n",
    "        neuron_gain = 0.0\n",
    "        if my_mode == 'max':\n",
    "            if bound_est > metric_bound:\n",
    "                if metric_bound > 0.0:\n",
    "                    neuron_gain = bound_est/metric_bound - 1.0\n",
    "                    if neuron_gain <= min_neuron_gain:\n",
    "                        print('NETs w {} neurons didnt improve {} {:.2f} neuron gain {:.2f} / min {:.2f}!'.format(total_neurons, val_metric_name, bound_est, 100.0*neuron_gain, 100.0*min_neuron_gain))\n",
    "                        bound_didnt_improve = True\n",
    "                        break\n",
    "                    else:\n",
    "                        print('NETs Neuron Gain w/ {} neurons: {:.2f} >> {:.2f} = {:.2f}%'.format(total_neurons, metric_bound, bound_est ,100.0*neuron_gain))\n",
    "                else:\n",
    "                    print('Best Config Bound Estimation{:.2f}'.format(bound_est))\n",
    "            else:\n",
    "                print('No Bound Gain on {} neurons for {}: {:.2f} >> {:.2f}'.format(total_neurons, best_optimizer, metric_bound, bound_est))\n",
    "                bound_didnt_improve = True\n",
    "                break\n",
    "        elif my_mode == 'min':\n",
    "            if bound_est < metric_bound:\n",
    "                if metric_bound > 0.0:\n",
    "                    neuron_gain = 1.0 - bound_est/metric_bound\n",
    "                    if neuron_gain <= min_neuron_gain:\n",
    "                        print('NETs w {} neurons didnt improve {} {:.2f} neuron gain {:.2f} / min {:.2f}!'.format(total_neurons, val_metric_name, bound_est, 100.0*neuron_gain, 100.0*min_neuron_gain))\n",
    "                        bound_didnt_improve = True\n",
    "                        break\n",
    "                    else:\n",
    "                        print('NETs Neuron Gain w/ {} neurons: {:.2f} >> {:.2f} = {:.2f}%'.format(total_neurons, metric_bound, bound_est ,100.0*neuron_gain))\n",
    "                else:\n",
    "                    print('Best Config Bound Estimation{:.2f}'.format(bound_est))\n",
    "            else:\n",
    "                print('No Bound Gain on {} neurons for {}: {:.2f} >> {:.2f}'.format(total_neurons, best_optimizer, metric_bound, bound_est))\n",
    "                bound_didnt_improve = True\n",
    "                break\n",
    "\n",
    "    else:\n",
    "        print('BEST CONFIG {} & best quality for {}: {:.2f}'.format(best_config, best_optimizer.upper(), bound_est))\n",
    "    \n",
    "    metric_bound = bound_est\n",
    "\n",
    "    # ALTER CONFIG FROM BEST CONFIG IF NEEDED\n",
    "    if maximized_metrics or dont_need_extra_neurons or bound_didnt_improve:\n",
    "        still_searching = False\n",
    "    else:\n",
    "        current_configurations = best_config + search_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROLL BACK TO LESS NEURON IF DIDNT IMPROVE\n",
    "if bound_didnt_improve and rollback_on_no_bound_gain:\n",
    "    best_row = df_results[(df_results.neurons == best_config.sum() - 1) & df_results.is_best].tail(1)\n",
    "    best_net_name = best_row['model_name'].values[0]\n",
    "    best_optimizer = best_row['optimizer'].values[0]\n",
    "    best_net = best_row['net'].values[0]\n",
    "    best_config = best_row['net_config'].values[0]\n",
    "    best_features = best_row['features'].values[0]\n",
    "    best_neurons = best_row['neurons'].values[0]\n",
    "    best_metric = best_row[metric_name].values[0]\n",
    "    best_metric_val = best_row[val_metric_name].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a 1D array, got an array with shape (169, 47)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Y'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/pandas/core/frame.py:3799\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3798\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3799\u001b[0m     loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_info_axis\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3800\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m   3801\u001b[0m     \u001b[39m# This item wasn't present, just insert at end\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Y'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/higoreller/Development/pos_machine_learning/src/class/portfolio_project/occurences_nature_2_NN.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/higoreller/Development/pos_machine_learning/src/class/portfolio_project/occurences_nature_2_NN.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# PLOT Y Vs YEST\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/higoreller/Development/pos_machine_learning/src/class/portfolio_project/occurences_nature_2_NN.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m df_result \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mDataFrame(index\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39mindex)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/higoreller/Development/pos_machine_learning/src/class/portfolio_project/occurences_nature_2_NN.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m df_result[\u001b[39m'\u001b[39m\u001b[39mY\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m Y\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/higoreller/Development/pos_machine_learning/src/class/portfolio_project/occurences_nature_2_NN.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m df_result[\u001b[39m'\u001b[39m\u001b[39mY_est\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m Y_est\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/higoreller/Development/pos_machine_learning/src/class/portfolio_project/occurences_nature_2_NN.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m df_result[\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_result[\u001b[39m'\u001b[39m\u001b[39mY_est\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m df_result[\u001b[39m'\u001b[39m\u001b[39mY\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/pandas/core/frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3653\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3654\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/pandas/core/frame.py:3845\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3842\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(existing_piece, DataFrame):\n\u001b[1;32m   3843\u001b[0m             value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtile(value, (\u001b[39mlen\u001b[39m(existing_piece\u001b[39m.\u001b[39mcolumns), \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mT\n\u001b[0;32m-> 3845\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item_mgr(key, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/pandas/core/frame.py:3802\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3799\u001b[0m     loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39mget_loc(key)\n\u001b[1;32m   3800\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m   3801\u001b[0m     \u001b[39m# This item wasn't present, just insert at end\u001b[39;00m\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49minsert(\u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_info_axis), key, value)\n\u001b[1;32m   3803\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iset_item_mgr(loc, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/pandas/core/internals/managers.py:1235\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[0;34m(self, loc, item, value)\u001b[0m\n\u001b[1;32m   1233\u001b[0m     value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mT\n\u001b[1;32m   1234\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(value) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1236\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected a 1D array, got an array with shape \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1237\u001b[0m         )\n\u001b[1;32m   1238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1239\u001b[0m     value \u001b[39m=\u001b[39m ensure_block_shape(value, ndim\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected a 1D array, got an array with shape (169, 47)"
     ]
    }
   ],
   "source": [
    "# PREDICT\n",
    "ix_best_features = dfn['X'].columns.isin(best_features, level=1)\n",
    "Y_est_scaled = best_net.predict(X_scaled[:, ix_best_features], verbose=0)\n",
    "Y_est = Y_scaler.inverse_transform(Y_est_scaled)\n",
    "\n",
    "# PLOT Y Vs YEST\n",
    "df_result = pandas.DataFrame(index=df.index)\n",
    "df_result['Y'] = Y\n",
    "df_result['Y_est'] = Y_est\n",
    "df_result['r'] = df_result['Y_est'] - df_result['Y']\n",
    "df_result['rabs'] = df_result['r'].abs()\n",
    "df_result = df_result.join(df.loc[:, df.columns != reg_col])\n",
    "\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.12' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/higoreller/miniconda3/envs/condaenv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# STABLE RESIDUAL PLOT\n",
    "r_mean = df_result.r.median()\n",
    "r_std = df_result.r.std()\n",
    "r2 = r2_score(df_result.Y.to_numpy(), df_result.Y_est.to_numpy())\n",
    "\n",
    "fig = pyplot.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(121)\n",
    "lines = seaborn.scatterplot(data=df_result, x='Y', y='Y_est', size='rabs', ax=ax, label='residuo', color='green')\n",
    "_ = ax.plot([df_result.Y.min(), df_result.Y.max()], [df_result.Y.min(), df_result.Y.max()], color='green', label='ref')\n",
    "_ = ax.grid(alpha=0.2)\n",
    "_ = ax.set_title('{} R2: {:.1f}%'.format(best_net_name,100.0*r2), size=20)\n",
    "ax2 = ax.twinx()\n",
    "_ = seaborn.kdeplot(data=df_result, x='Y', ax=ax2, label='Y', color='green', fill=True, alpha=0.1, linewidth=0.7)\n",
    "_ = seaborn.kdeplot(data=df_result, x='Y_est', ax=ax2, label='Y_est', color='green', fill=True, alpha=0.5, linewidth=0.7)\n",
    "_ = ax2.set_ylabel('')\n",
    "_ = ax2.set_yticks([])\n",
    "_ = ax.legend(loc='upper right')\n",
    "_ = ax2.legend(loc='lower right')\n",
    "ax3 = fig.add_subplot(122)\n",
    "_ = seaborn.scatterplot(data=df_result, x='r', y='Y', ax=ax3, label='residuo', color='red')\n",
    "ax4 = ax3.twinx()\n",
    "_ = seaborn.kdeplot(data=df_result, x='r', ax=ax4, label='residuo', color='red', fill=True, alpha=0.5, linewidth=0.7)\n",
    "_ = ax4.grid(alpha=0.2)\n",
    "_ = ax4.set_ylabel('')\n",
    "_ = ax4.set_yticks([])\n",
    "_ = ax4.set_title('Residuo: {:.2f} +- {:.2f}'.format(r_mean, r_std), size=20)\n",
    "_ = ax3.plot([r_mean, r_mean], [df_result.Y_est.min(), df_result.Y_est.max()], '--', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.12' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/higoreller/miniconda3/envs/condaenv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_result.Y_est.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.12' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/higoreller/miniconda3/envs/condaenv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# SCATTER PLOT\n",
    "resplot_var = list(df.columns[df.columns != reg_col])\n",
    "resplot_var.append('r')\n",
    "g2 = seaborn.pairplot(df_result[resplot_var], hue='naturezas', height=3, diag_kind='kde')\n",
    "# _ = g2.map_lower(seaborn.kdeplot, levels=1, color=\".2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.12' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/higoreller/miniconda3/envs/condaenv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "81a3580d9119b5a6c386c26f975d9316f07a8b79ce368947d33d8f384f33fbaa"
   }
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "a71a1ad02e237783013e73aa0c06d9608f113229b1c33e91c79bde9fc7f65af1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
