{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIVARIATE NONLINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot\n",
    "import seaborn\n",
    "import itertools\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, r2_score\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUGGING ANNOYING WARNING\n",
    "# tensorflow.debugging.set_log_device_placement(True)\n",
    "from tensorflow.python.data.util import options as options_lib\n",
    "from tensorflow.python.data.experimental import DistributeOptions, AutoShardPolicy\n",
    "\n",
    "DistributeOptions.auto_shard_policy = options_lib.create_option(\n",
    "    name=\"auto_shard_policy\",\n",
    "    ty=AutoShardPolicy,\n",
    "    docstring=\"The type of sharding to use. See \"\n",
    "    \"`tf.data.experimental.AutoShardPolicy` for additional information.\",\n",
    "    default_factory=lambda: AutoShardPolicy.DATA,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT PARAMETERS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/higoreller/miniconda3/envs/condaenv/lib/python3.9/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Cell F221384 is marked as a date but the serial value -736954.9663425926 is outside the limits for dates. The cell will be treated as an error.\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "# DATA PRE-PREPARATION\n",
    "file_path = '../../../dataset/occurrences.xlsx'\n",
    "\n",
    "df = pandas.read_excel(file_path)\n",
    "df = df.drop([\"rai\", \"obm_afeto\", \"qualificacao\", \"sexo\"], axis=1).loc[0:5000,:] \n",
    "\n",
    "#REMOVING NULL VALUES\n",
    "df.loc[pandas.isnull(df[\"data\"])]\n",
    "df.loc[pandas.isnull(df[\"naturezas\"])]\n",
    "df.loc[pandas.isnull(df[\"bairro_cidade\"])]\n",
    "df.loc[pandas.isnull(df[\"tr\"])]\n",
    "df.loc[pandas.isnull(df[\"obm_escala\"])]\n",
    "\n",
    "df = df.loc[df[\"bairro_cidade\"] != \"(null)\"]\n",
    "df = df.loc[df[\"recurso\"] != \"(null)\"]\n",
    "df = df.loc[df[\"tr\"] != \"(null)\"]\n",
    "df = df.loc[df[\"obm_escala\"] != \"(null)\"]\n",
    "\n",
    "#TRANSFORMING \"data\" COLUMN INTO NEW COLUMNS \"dia\" e \"periodo\". ALSO TRANSFORMING \"tr\" COLUMN INTO \"tempo_resposta\" COLUMN\n",
    "\n",
    "def day_name(timestamp):\n",
    "    weekdays = ('Segunda-feira', 'Terça-feira', 'Quarta-feira', 'Quinta-feira', 'Sexta-feira', 'Sábado', 'Domingo')\n",
    "    return weekdays[timestamp.weekday()]\n",
    "\n",
    "def period_of_day(timestamp):\n",
    "    period = (\"Madrugada\", \"Matutino\", \"Vespertino\", \"Noturno\")\n",
    "    # Madrugada 00:00 às 05:59\n",
    "    # Matutino 06:00 às 11:59\n",
    "    # Vespertino 12:00 às 17:59\n",
    "    # Noturno 18:00 às 23:59\n",
    "    if timestamp.hour >= 0 and timestamp.hour < 6:\n",
    "        return period[0]\n",
    "    elif timestamp.hour >= 6 and timestamp.hour < 12:\n",
    "        return period[1]\n",
    "    elif timestamp.hour >= 12 and timestamp.hour < 18:\n",
    "        return period[2]\n",
    "    elif timestamp.hour >= 18 and timestamp.hour < 24:\n",
    "        return period[3]\n",
    "\n",
    "\n",
    "\n",
    "def response_time(response_time):\n",
    "    # Muito rápido 0 a 10 minutos\n",
    "    # Rápido 10 a 15 minutos\n",
    "    # Médio 15 a 20 minutos\n",
    "    # Longo 20 a 30 minutos\n",
    "    # Muito longo 30 a 45 minutos\n",
    "    # Extremamente longo > 45 minutos\n",
    "\n",
    "    response_time_metric = (\"Muito rápido\", \"Rápido\", \"Médio\", \"Longo\", \"Muito longo\", \"Extremamente longo\")\n",
    "\n",
    "    if type(response_time) is datetime.time:\n",
    "\n",
    "        total_time_in_minutes = response_time.hour*60 + response_time.minute + response_time.second/60\n",
    "\n",
    "        if total_time_in_minutes >= 0 and total_time_in_minutes <= 10:\n",
    "            return response_time_metric[0]\n",
    "        elif total_time_in_minutes > 10 and total_time_in_minutes <= 15:\n",
    "            return response_time_metric[1]\n",
    "        elif total_time_in_minutes > 15 and total_time_in_minutes <= 20:\n",
    "            return response_time_metric[2]\n",
    "        elif total_time_in_minutes > 20 and total_time_in_minutes <= 30:\n",
    "            return response_time_metric[3]\n",
    "        elif total_time_in_minutes > 30 and total_time_in_minutes <= 45:\n",
    "            return response_time_metric[4]\n",
    "        elif total_time_in_minutes > 45:\n",
    "            return response_time_metric[5]\n",
    "        \n",
    "#Lembrar de remover os valores que não são datetime.time do df[\"tr\"]\n",
    "df.loc[:, \"dia\"] = df[\"data\"].apply(day_name)\n",
    "df.loc[:, \"periodo\"] = df[\"data\"].apply(period_of_day)\n",
    "df.loc[:, \"tempo_resposta\"] = df[\"tr\"].apply(response_time)\n",
    "\n",
    "#REMOVING \"DATA\" AND \"TR\" COLUMNS\n",
    "\n",
    "df = df.drop([\"data\", \"tr\"], axis=1)\n",
    "\n",
    "#Removing None values\n",
    "df = df.dropna()\n",
    "df = df.mask(df.eq('None')).dropna()\n",
    "df = df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PARAMETERS\n",
    "\n",
    "var_types = {'naturezas' : 'str',\n",
    "             'bairro_cidade' : 'str',\n",
    "             'recurso' : 'str',\n",
    "             'dia': 'str',\n",
    "             'periodo': 'str',\n",
    "             'tempo_resposta': 'str',\n",
    "             'obm_escala': 'str',\n",
    "             }\n",
    "\n",
    "# COOK PARAMETERS\n",
    "reg_col = 'naturezas'\n",
    "folding_sampler = 'naturezas'\n",
    "my_metric = 'mse'\n",
    "relevant_features = 4\n",
    "my_patience = 50\n",
    "min_improvement = 0.01\n",
    "min_neuron_gain = 0.025\n",
    "random_seed = 42\n",
    "n_k_folds = 5\n",
    "learning_rate = 0.01\n",
    "hidden_activations = ['linear', 'sigmoid']\n",
    "print_anyway = True\n",
    "rollback_on_no_bound_gain = True\n",
    "my_optimizers = ['adam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT AND CONVERT\n",
    "for input_col in var_types.keys():\n",
    "    df[input_col] = df[input_col].astype(var_types[input_col])\n",
    "\n",
    "# SCATTER PLOT\n",
    "#g = seaborn.pairplot(df, hue='naturezas', height=3, diag_kind='kde')\n",
    "#_ = g.map_lower(seaborn.kdeplot, levels=1, color=\".2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROBUST COOKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">X</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">categorical</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">categorical</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>10ª CIBM - POSSE</th>\n",
       "      <th>10º BBM - CATALÃO</th>\n",
       "      <th>11ª CIBM - URUAÇU</th>\n",
       "      <th>11º BBM - PORANGATU</th>\n",
       "      <th>12ª CIBM - MORRINHOS</th>\n",
       "      <th>12º BBM - GOIÁS</th>\n",
       "      <th>13ª CIBM - IPORÁ</th>\n",
       "      <th>13º BBM - JATAÍ</th>\n",
       "      <th>14ª CIBM - PIRES DO RIO</th>\n",
       "      <th>14º BBM - SENADOR CANEDO</th>\n",
       "      <th>...</th>\n",
       "      <th>RESGATE (3)-&gt;TENTATIVA DE AUTO-EXTERMÍNIO (309)-&gt;ENFORCAMENTO (30902)</th>\n",
       "      <th>RESGATE (3)-&gt;TENTATIVA DE AUTO-EXTERMÍNIO (309)-&gt;ENVENENAMENTO (30903)</th>\n",
       "      <th>RESGATE (3)-&gt;TENTATIVA DE AUTO-EXTERMÍNIO (309)-&gt;OUTRA / TENTATIVA DE AUTO-EXTERMÍNIO (30999)</th>\n",
       "      <th>RESGATE (3)-&gt;TENTATIVA DE AUTO-EXTERMÍNIO (309)-&gt;POR ARMA BRANCA (30904)</th>\n",
       "      <th>RESGATE (3)-&gt;TRANSPORTE (310)-&gt;DE RECÉM NASCIDO (31002)</th>\n",
       "      <th>RESGATE (3)-&gt;TRANSPORTE (310)-&gt;HOSPITAL X RESIDÊNCIA (CIVIL) (31003)</th>\n",
       "      <th>RESGATE (3)-&gt;TRANSPORTE (310)-&gt;HOSPITAL X RESIDÊNCIA (MILITAR) (31004)</th>\n",
       "      <th>RESGATE (3)-&gt;TRANSPORTE (310)-&gt;INTRA HOSPITALAR (CIVIL) (31005)</th>\n",
       "      <th>RESGATE (3)-&gt;TRANSPORTE (310)-&gt;INTRA HOSPITALAR (MILITAR) (31006)</th>\n",
       "      <th>RESGATE (3)-&gt;TRANSPORTE (310)-&gt;OUTRO / TRANSPORTE (31099)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3694 rows × 1669 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    X                                                          \\\n",
       "          categorical                                                           \n",
       "     10ª CIBM - POSSE 10º BBM - CATALÃO 11ª CIBM - URUAÇU 11º BBM - PORANGATU   \n",
       "1                 0.0               0.0               0.0                 0.0   \n",
       "2                 0.0               0.0               0.0                 0.0   \n",
       "3                 0.0               0.0               0.0                 0.0   \n",
       "4                 0.0               0.0               0.0                 0.0   \n",
       "5                 0.0               1.0               0.0                 0.0   \n",
       "...               ...               ...               ...                 ...   \n",
       "4996              0.0               0.0               0.0                 0.0   \n",
       "4997              0.0               0.0               0.0                 0.0   \n",
       "4998              0.0               0.0               0.0                 0.0   \n",
       "4999              0.0               0.0               0.0                 0.0   \n",
       "5000              0.0               0.0               0.0                 0.0   \n",
       "\n",
       "                                                                            \\\n",
       "                                                                             \n",
       "     12ª CIBM - MORRINHOS 12º BBM - GOIÁS 13ª CIBM - IPORÁ 13º BBM - JATAÍ   \n",
       "1                     0.0             0.0              0.0             0.0   \n",
       "2                     0.0             0.0              0.0             0.0   \n",
       "3                     0.0             0.0              0.0             0.0   \n",
       "4                     0.0             0.0              0.0             0.0   \n",
       "5                     0.0             0.0              0.0             0.0   \n",
       "...                   ...             ...              ...             ...   \n",
       "4996                  0.0             0.0              0.0             0.0   \n",
       "4997                  0.0             0.0              0.0             1.0   \n",
       "4998                  1.0             0.0              0.0             0.0   \n",
       "4999                  0.0             0.0              0.0             0.0   \n",
       "5000                  0.0             0.0              0.0             0.0   \n",
       "\n",
       "                                                       ...  \\\n",
       "                                                       ...   \n",
       "     14ª CIBM - PIRES DO RIO 14º BBM - SENADOR CANEDO  ...   \n",
       "1                        0.0                      0.0  ...   \n",
       "2                        0.0                      0.0  ...   \n",
       "3                        0.0                      0.0  ...   \n",
       "4                        0.0                      0.0  ...   \n",
       "5                        0.0                      0.0  ...   \n",
       "...                      ...                      ...  ...   \n",
       "4996                     0.0                      0.0  ...   \n",
       "4997                     0.0                      0.0  ...   \n",
       "4998                     0.0                      0.0  ...   \n",
       "4999                     0.0                      0.0  ...   \n",
       "5000                     0.0                      0.0  ...   \n",
       "\n",
       "                                                                         Y  \\\n",
       "                                                               categorical   \n",
       "     RESGATE (3)->TENTATIVA DE AUTO-EXTERMÍNIO (309)->ENFORCAMENTO (30902)   \n",
       "1                                                   0.0                      \n",
       "2                                                   0.0                      \n",
       "3                                                   0.0                      \n",
       "4                                                   0.0                      \n",
       "5                                                   0.0                      \n",
       "...                                                 ...                      \n",
       "4996                                                0.0                      \n",
       "4997                                                0.0                      \n",
       "4998                                                0.0                      \n",
       "4999                                                0.0                      \n",
       "5000                                                0.0                      \n",
       "\n",
       "                                                                             \\\n",
       "                                                                              \n",
       "     RESGATE (3)->TENTATIVA DE AUTO-EXTERMÍNIO (309)->ENVENENAMENTO (30903)   \n",
       "1                                                   0.0                       \n",
       "2                                                   0.0                       \n",
       "3                                                   0.0                       \n",
       "4                                                   0.0                       \n",
       "5                                                   0.0                       \n",
       "...                                                 ...                       \n",
       "4996                                                0.0                       \n",
       "4997                                                0.0                       \n",
       "4998                                                0.0                       \n",
       "4999                                                0.0                       \n",
       "5000                                                0.0                       \n",
       "\n",
       "                                                                                                    \\\n",
       "                                                                                                     \n",
       "     RESGATE (3)->TENTATIVA DE AUTO-EXTERMÍNIO (309)->OUTRA / TENTATIVA DE AUTO-EXTERMÍNIO (30999)   \n",
       "1                                                   0.0                                              \n",
       "2                                                   0.0                                              \n",
       "3                                                   0.0                                              \n",
       "4                                                   0.0                                              \n",
       "5                                                   0.0                                              \n",
       "...                                                 ...                                              \n",
       "4996                                                0.0                                              \n",
       "4997                                                0.0                                              \n",
       "4998                                                0.0                                              \n",
       "4999                                                0.0                                              \n",
       "5000                                                0.0                                              \n",
       "\n",
       "                                                                               \\\n",
       "                                                                                \n",
       "     RESGATE (3)->TENTATIVA DE AUTO-EXTERMÍNIO (309)->POR ARMA BRANCA (30904)   \n",
       "1                                                   0.0                         \n",
       "2                                                   0.0                         \n",
       "3                                                   0.0                         \n",
       "4                                                   0.0                         \n",
       "5                                                   0.0                         \n",
       "...                                                 ...                         \n",
       "4996                                                0.0                         \n",
       "4997                                                0.0                         \n",
       "4998                                                0.0                         \n",
       "4999                                                0.0                         \n",
       "5000                                                0.0                         \n",
       "\n",
       "                                                              \\\n",
       "                                                               \n",
       "     RESGATE (3)->TRANSPORTE (310)->DE RECÉM NASCIDO (31002)   \n",
       "1                                                   0.0        \n",
       "2                                                   0.0        \n",
       "3                                                   0.0        \n",
       "4                                                   0.0        \n",
       "5                                                   0.0        \n",
       "...                                                 ...        \n",
       "4996                                                0.0        \n",
       "4997                                                0.0        \n",
       "4998                                                0.0        \n",
       "4999                                                0.0        \n",
       "5000                                                0.0        \n",
       "\n",
       "                                                                           \\\n",
       "                                                                            \n",
       "     RESGATE (3)->TRANSPORTE (310)->HOSPITAL X RESIDÊNCIA (CIVIL) (31003)   \n",
       "1                                                   0.0                     \n",
       "2                                                   0.0                     \n",
       "3                                                   0.0                     \n",
       "4                                                   0.0                     \n",
       "5                                                   0.0                     \n",
       "...                                                 ...                     \n",
       "4996                                                0.0                     \n",
       "4997                                                0.0                     \n",
       "4998                                                0.0                     \n",
       "4999                                                0.0                     \n",
       "5000                                                0.0                     \n",
       "\n",
       "                                                                             \\\n",
       "                                                                              \n",
       "     RESGATE (3)->TRANSPORTE (310)->HOSPITAL X RESIDÊNCIA (MILITAR) (31004)   \n",
       "1                                                   0.0                       \n",
       "2                                                   0.0                       \n",
       "3                                                   0.0                       \n",
       "4                                                   0.0                       \n",
       "5                                                   0.0                       \n",
       "...                                                 ...                       \n",
       "4996                                                0.0                       \n",
       "4997                                                0.0                       \n",
       "4998                                                0.0                       \n",
       "4999                                                0.0                       \n",
       "5000                                                0.0                       \n",
       "\n",
       "                                                                      \\\n",
       "                                                                       \n",
       "     RESGATE (3)->TRANSPORTE (310)->INTRA HOSPITALAR (CIVIL) (31005)   \n",
       "1                                                   0.0                \n",
       "2                                                   0.0                \n",
       "3                                                   0.0                \n",
       "4                                                   0.0                \n",
       "5                                                   0.0                \n",
       "...                                                 ...                \n",
       "4996                                                0.0                \n",
       "4997                                                0.0                \n",
       "4998                                                0.0                \n",
       "4999                                                0.0                \n",
       "5000                                                0.0                \n",
       "\n",
       "                                                                        \\\n",
       "                                                                         \n",
       "     RESGATE (3)->TRANSPORTE (310)->INTRA HOSPITALAR (MILITAR) (31006)   \n",
       "1                                                   0.0                  \n",
       "2                                                   0.0                  \n",
       "3                                                   0.0                  \n",
       "4                                                   0.0                  \n",
       "5                                                   0.0                  \n",
       "...                                                 ...                  \n",
       "4996                                                0.0                  \n",
       "4997                                                0.0                  \n",
       "4998                                                0.0                  \n",
       "4999                                                0.0                  \n",
       "5000                                                0.0                  \n",
       "\n",
       "                                                                \n",
       "                                                                \n",
       "     RESGATE (3)->TRANSPORTE (310)->OUTRO / TRANSPORTE (31099)  \n",
       "1                                                   0.0         \n",
       "2                                                   0.0         \n",
       "3                                                   0.0         \n",
       "4                                                   0.0         \n",
       "5                                                   0.0         \n",
       "...                                                 ...         \n",
       "4996                                                0.0         \n",
       "4997                                                0.0         \n",
       "4998                                                0.0         \n",
       "4999                                                0.0         \n",
       "5000                                                0.0         \n",
       "\n",
       "[3694 rows x 1669 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SET THE RANDOM SEED\n",
    "numpy.random.seed(random_seed)\n",
    "tensorflow.random.set_seed(random_seed)\n",
    "\n",
    "# QUANTIFY REPRESENTATION \n",
    "dfn_mi_list = []\n",
    "dfn_data_list = []\n",
    "for my_var in var_types.keys():\n",
    "    if my_var == reg_col:\n",
    "        col_class = 'Y'\n",
    "    else:\n",
    "        col_class = 'X'\n",
    "\n",
    "    if var_types[my_var] == 'float': # NUMERIC DATA\n",
    "        dfn_mi_list.append((col_class, 'continuous', my_var))\n",
    "        dfn_data_list.append(df[[my_var]].values)\n",
    "\n",
    "    elif var_types[my_var] == 'str': # CATEGORICAL DATA\n",
    "        one_hot = OneHotEncoder(sparse=False)\n",
    "        var_cat = df[[my_var]].to_numpy()\n",
    "        one_hot.fit(var_cat)\n",
    "        cat_df = pandas.DataFrame(one_hot.transform(var_cat))\n",
    "        cat_df.columns = one_hot.categories_\n",
    "        for cat in cat_df.columns:\n",
    "            dfn_mi_list.append((col_class, 'categorical', cat[0]))\n",
    "            dfn_data_list.append(cat_df[[cat]].values)\n",
    "\n",
    "dfn_mi = pandas.MultiIndex.from_tuples(dfn_mi_list)\n",
    "dfn = pandas.DataFrame(index=df.index, columns=dfn_mi, data=numpy.concatenate(dfn_data_list, axis=1))\n",
    "dfn = dfn.sort_index(axis=1)\n",
    "dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "# NUMPY MATRIX FOR TRAINING\n",
    "X = dfn['X'].to_numpy()\n",
    "my_vars = list(dfn['X'].columns.get_level_values(1))\n",
    "Y = dfn['Y'].to_numpy()\n",
    "\n",
    "# NORMALIZE VARIABLES\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler = X_scaler.fit(X)\n",
    "X_scaled = X_scaler.transform(X)\n",
    "\n",
    "# TRANSFORM Y\n",
    "Y_scaler = None\n",
    "if var_types[reg_col] == 'float': # IF REGRESSION NORMALIZE\n",
    "    Y_scaler = StandardScaler()\n",
    "    Y_scaler = Y_scaler.fit(Y)\n",
    "    Y_scaled = Y_scaler.transform(Y)\n",
    "else:\n",
    "    Y_scaled = Y\n",
    "\n",
    "# Y SAMPLING\n",
    "Y_sample = df[[folding_sampler]].to_numpy()\n",
    "\n",
    "# GET STRATIFIED FOLDS\n",
    "sk_folds = StratifiedKFold(n_splits=n_k_folds)\n",
    "sk_folds.get_n_splits(X_scaled, Y_sample)\n",
    "\n",
    "# TRAINING LOOP\n",
    "n_classes = dfn['Y'].columns.shape[0]\n",
    "hidden_layers = 1\n",
    "\n",
    "# PATTERN SEARCH\n",
    "search_vector = numpy.identity(len(hidden_activations), dtype=int)\n",
    "current_configurations = search_vector\n",
    "\n",
    "still_searching = True\n",
    "best_net_name = None\n",
    "best_net = None\n",
    "best_config = None\n",
    "\n",
    "if my_metric == 'mse':\n",
    "    my_mode = 'min'\n",
    "    best_metric = 1.0\n",
    "    best_metric_val = 1.0\n",
    "    metric_bound = 1000.0\n",
    "else:\n",
    "    my_mode = 'max'\n",
    "    best_metric = 0.0\n",
    "    best_metric_val = 0.0\n",
    "    metric_bound = 0.0\n",
    "\n",
    "\n",
    "result_list = []\n",
    "\n",
    "# RUNNING ON GPU AND CPU\n",
    "strategy = tensorflow.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COOKING BEST NETWORK STARTED...\n",
      "\n",
      "CONFIG: [1 0]\n",
      "FOLD: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/higoreller/miniconda3/envs/condaenv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "2022-08-16 19:56:32.830187: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-16 19:57:03.576622: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-16 19:57:34.310292: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-16 19:58:04.407056: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-16 19:58:34.850686: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-16 19:59:05.000692: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-16 19:59:35.269429: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-16 20:00:05.882576: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-16 20:00:36.052333: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-16 20:01:06.223432: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-16 20:01:36.434483: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-16 20:02:06.524078: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-16 20:02:36.790670: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-16 20:03:06.925292: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-16 20:03:37.152102: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-16 20:04:07.481406: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-08-16 20:04:37.837524: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/higoreller/Development/pos_machine_learning/src/class/portfolio_project/occurences_nature_2_NN.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/higoreller/Development/pos_machine_learning/src/class/portfolio_project/occurences_nature_2_NN.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m X_relevance \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mcopy(X_scaled)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/higoreller/Development/pos_machine_learning/src/class/portfolio_project/occurences_nature_2_NN.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m X_relevance[:, my_vars \u001b[39m==\u001b[39m feature] \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/higoreller/Development/pos_machine_learning/src/class/portfolio_project/occurences_nature_2_NN.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m Y_est_relevance \u001b[39m=\u001b[39m my_net\u001b[39m.\u001b[39;49mpredict(X_relevance, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/higoreller/Development/pos_machine_learning/src/class/portfolio_project/occurences_nature_2_NN.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m Y_relevance \u001b[39m=\u001b[39m (Y_est \u001b[39m-\u001b[39m Y_est_relevance)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/higoreller/Development/pos_machine_learning/src/class/portfolio_project/occurences_nature_2_NN.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m feature_relevance \u001b[39m=\u001b[39m Y_relevance\u001b[39m.\u001b[39msum()\u001b[39m/\u001b[39mY_relevance\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/keras/engine/training.py:1982\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1980\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   1981\u001b[0m   callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 1982\u001b[0m   tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[1;32m   1983\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1984\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/condaenv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('COOKING BEST NETWORK STARTED...\\n')\n",
    "while still_searching:\n",
    "    for net_config in current_configurations:\n",
    "        print('CONFIG: {}'.format(net_config))\n",
    "        ix_fold = 1\n",
    "        for train_index, test_index in sk_folds.split(X_scaled, Y_sample):\n",
    "            print('FOLD: {}/{}'.format(ix_fold, n_k_folds))\n",
    "\n",
    "            # GET STRATIFIED DATA\n",
    "            X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "            Y_train, Y_test = Y_scaled[train_index], Y_scaled[test_index]\n",
    "            for optimizer in my_optimizers:\n",
    "\n",
    "                # Open a strategy scope and create/restore the model\n",
    "                with strategy.scope():\n",
    "                    # DECLARE OPTIMIZERS INSIDE SCOPE\n",
    "                    _optimizers = {'adagrad': tensorflow.keras.optimizers.Adagrad(learning_rate=learning_rate),\n",
    "                                   'rmsprop': tensorflow.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "                                   'adam': tensorflow.keras.optimizers.Adam(learning_rate=learning_rate)}\n",
    "                    # DECLARE NET\n",
    "                    inputs = keras.Input(shape=(X_train.shape[1], ))\n",
    "                    hidden_layer_list = []\n",
    "                    net_name = ''\n",
    "                    for ix_activation in numpy.arange(len(net_config)):\n",
    "                        f_activation = hidden_activations[ix_activation]\n",
    "                        n_neuron = net_config[ix_activation]\n",
    "                        if n_neuron > 0:\n",
    "                            temp_hidden_layer = keras.layers.Dense(n_neuron, activation=f_activation)(inputs)\n",
    "                            hidden_layer_list.append(temp_hidden_layer)\n",
    "                            net_name += '{}{}'.format(f_activation, n_neuron)\n",
    "                    if len(hidden_layer_list) > 1:\n",
    "                        hidden = keras.layers.Concatenate(axis=1)(hidden_layer_list)\n",
    "                    else:\n",
    "                        hidden = hidden_layer_list[0]\n",
    "                    outputs = keras.layers.Dense(n_classes, activation='linear')(hidden)\n",
    "                    model_name = '{}_{}_F{}_WRAPPER'.format(net_name.upper(), optimizer.upper(), ix_fold)\n",
    "                    my_net = keras.Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "\n",
    "                # COMPILE NET\n",
    "                metric_name = my_metric.lower()\n",
    "                val_metric_name = 'val_{}'.format(metric_name)\n",
    "                my_net.compile(optimizer=_optimizers[optimizer], loss='mse', metrics=[my_metric])\n",
    "                es_loss = tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', patience=my_patience, restore_best_weights=True)\n",
    "                es_metric = tensorflow.keras.callbacks.EarlyStopping(monitor=metric_name, mode=my_mode, patience=my_patience, min_delta=min_improvement)\n",
    "                es_val_metric = tensorflow.keras.callbacks.EarlyStopping(monitor=val_metric_name, mode=my_mode,\n",
    "                                                                         patience=n_k_folds*my_patience, min_delta=min_improvement)\n",
    "\n",
    "                # FIT WRAPPER\n",
    "                history = my_net.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=X_train.shape[0],\n",
    "                                    epochs=10*my_patience, verbose=0, callbacks=[es_loss, es_metric, es_val_metric])\n",
    "\n",
    "                # CALCULATE VARIABLE RELEVANCE\n",
    "                Y_est = my_net.predict(X_scaled, verbose=0)\n",
    "                relevance_dict = {}\n",
    "                for feature in my_vars:\n",
    "                    X_relevance = numpy.copy(X_scaled)\n",
    "                    X_relevance[:, my_vars == feature] = 0.0\n",
    "                    Y_est_relevance = my_net.predict(X_relevance, verbose=0)\n",
    "                    Y_relevance = (Y_est - Y_est_relevance)**2\n",
    "                    feature_relevance = Y_relevance.sum()/Y_relevance.shape[0]\n",
    "                    relevance_dict[feature] = feature_relevance\n",
    "                s_relevance = pandas.Series(relevance_dict)\n",
    "                s_relevance_norm = s_relevance/s_relevance.max()\n",
    "                s_relevance_norm = s_relevance_norm.sort_values(ascending=False).head(relevant_features)\n",
    "                selected_features = list(s_relevance_norm.index.values)\n",
    "                selected_relevance = list(100.0*s_relevance_norm.values)\n",
    "\n",
    "                # FINAL NET\n",
    "                with strategy.scope():\n",
    "                    inputs = keras.Input(shape=(len(selected_features), ))\n",
    "                    hidden_layer_list = []\n",
    "                    net_name = ''\n",
    "                    for ix_activation in numpy.arange(len(net_config)):\n",
    "                        f_activation = hidden_activations[ix_activation]\n",
    "                        n_neuron = net_config[ix_activation]\n",
    "                        if n_neuron > 0:\n",
    "                            temp_hidden_layer = keras.layers.Dense(n_neuron, activation=f_activation)(inputs)\n",
    "                            hidden_layer_list.append(temp_hidden_layer)\n",
    "                            net_name += '{}{}'.format(f_activation, n_neuron)\n",
    "                    if len(hidden_layer_list) > 1:\n",
    "                        hidden = keras.layers.Concatenate(axis=1)(hidden_layer_list)\n",
    "                    else:\n",
    "                        hidden = hidden_layer_list[0]\n",
    "                    outputs = keras.layers.Dense(n_classes, activation='linear')(hidden)\n",
    "                    model_name = '{}_{}_F{}'.format(net_name.upper(), optimizer.upper(), ix_fold)\n",
    "                    my_net = keras.Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "\n",
    "                # COMPILE NET\n",
    "                metric_name = my_metric.lower()\n",
    "                val_metric_name = 'val_{}'.format(metric_name)\n",
    "                my_net.compile(optimizer=_optimizers[optimizer], loss='mse', metrics=[my_metric])\n",
    "                es_loss = tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', patience=my_patience, restore_best_weights=True)\n",
    "                es_metric = tensorflow.keras.callbacks.EarlyStopping(monitor=metric_name, mode=my_mode, patience=my_patience, min_delta=min_improvement)\n",
    "                es_val_metric = tensorflow.keras.callbacks.EarlyStopping(monitor=val_metric_name, mode=my_mode,\n",
    "                                                                        patience=n_k_folds*my_patience, min_delta=min_improvement)\n",
    "\n",
    "                # FIT WRAPPER\n",
    "                ix_relevant = dfn['X'].columns.get_level_values(1).isin(selected_features)\n",
    "                history = my_net.fit(X_train[:, ix_relevant], Y_train, validation_data=(X_test[:, ix_relevant], Y_test), batch_size=X_train.shape[0],\n",
    "                                    epochs=10*my_patience, verbose=0, callbacks=[es_loss, es_metric, es_val_metric])\n",
    "\n",
    "                # UNPACK TRAINING RESULTS\n",
    "                model_loss = history.history['loss'][-1]\n",
    "                model_val_loss = history.history['val_loss'][-1]\n",
    "                metric_val = history.history[metric_name][-1]\n",
    "                val_metric_val = history.history[val_metric_name][-1]\n",
    "                n_epochs = len(history.history['val_loss'])\n",
    "\n",
    "                # CHECK IF BEST NET\n",
    "                best_net_txt = ''\n",
    "                is_best = False\n",
    "                if my_mode == 'max':\n",
    "                    is_best = ((metric_val > best_metric + min_improvement) & (val_metric_val >= best_metric_val)) | ((metric_val >= best_metric) & (val_metric_val > best_metric_val + min_improvement))\n",
    "                elif my_mode == 'min':\n",
    "                    is_best = ((metric_val < best_metric - min_improvement) & (val_metric_val <= best_metric_val)) | ((metric_val <= best_metric) & (val_metric_val < best_metric_val - min_improvement))\n",
    "\n",
    "                if is_best:\n",
    "                    best_net_name = model_name\n",
    "                    best_optimizer = optimizer\n",
    "                    best_config = net_config\n",
    "                    best_features = selected_features\n",
    "                    best_relevance = selected_relevance\n",
    "                    best_net = my_net\n",
    "                    best_neurons = net_config.sum()\n",
    "                    best_metric = metric_val\n",
    "                    best_metric_val = val_metric_val\n",
    "                    best_net_txt = '**Best NET!**'\n",
    "\n",
    "                result_dict = {'model_name': model_name, 'optimizer': optimizer, 'net_config': net_config, 'neurons': net_config.sum(), 'fold': ix_fold, 'features': selected_features, 'relevance': selected_relevance, 'loss': model_loss,\n",
    "                    'val_loss': model_val_loss, metric_name: metric_val, val_metric_name: val_metric_val, 'epochs': n_epochs, 'is_best': is_best, 'net': my_net}\n",
    "                result_list.append(result_dict)\n",
    "                if is_best or print_anyway:\n",
    "                    print('{}_{} > epochs: {} loss: {:.2f} val_loss: {:.2f} {}: {:.2f} {}: {:.2f} {}'.format(model_name,'_'.join(selected_features), n_epochs, model_loss, model_val_loss, metric_name, metric_val, val_metric_name, val_metric_val, best_net_txt))\n",
    "\n",
    "                # IF MAXIMIZED METRICS BREAK\n",
    "                if my_mode == 'max':\n",
    "                    maximized_metrics = (val_metric_val == 1.0) & (metric_val == 1.0)\n",
    "                elif my_mode == 'min':\n",
    "                    maximized_metrics = (val_metric_val == 0.0) & (metric_val == 0.0)\n",
    "\n",
    "                if maximized_metrics:\n",
    "                    break\n",
    "            \n",
    "            if maximized_metrics:\n",
    "                break\n",
    "\n",
    "            ix_fold += 1\n",
    "\n",
    "        if maximized_metrics:\n",
    "            break\n",
    "\n",
    "    # TEST IF MORE NEURONS ARE NECESSARY\n",
    "    dont_need_extra_neurons = False\n",
    "    total_neurons = net_config.sum()\n",
    "\n",
    "    if total_neurons > 1:\n",
    "        \n",
    "        # INCREASING NEURONS DIDNT ACHIEVE BEST NET\n",
    "        if best_neurons < total_neurons:\n",
    "            dont_need_extra_neurons = True\n",
    "            print('NETs w {} neurons didnt improve {}!'.format(total_neurons, metric_name))\n",
    "            break\n",
    "    \n",
    "    # CALCULATE CONFIG BOUND\n",
    "    df_results = pandas.DataFrame(result_list)\n",
    "    ix_config = numpy.array([numpy.linalg.norm(best_config - x) for x in df_results.net_config]) == 0.0\n",
    "    if my_mode == 'max':\n",
    "        bound_est = df_results[(df_results.optimizer == best_optimizer) & ix_config][val_metric_name].min()\n",
    "    elif my_mode == 'min':\n",
    "        bound_est = df_results[(df_results.optimizer == best_optimizer) & ix_config][val_metric_name].max()\n",
    "\n",
    "    # TEST IF LOWER BOUND IMPROVED\n",
    "    bound_didnt_improve = False\n",
    "    if total_neurons > 1:\n",
    "        neuron_gain = 0.0\n",
    "        if my_mode == 'max':\n",
    "            if bound_est > metric_bound:\n",
    "                if metric_bound > 0.0:\n",
    "                    neuron_gain = bound_est/metric_bound - 1.0\n",
    "                    if neuron_gain <= min_neuron_gain:\n",
    "                        print('NETs w {} neurons didnt improve {} {:.2f} neuron gain {:.2f} / min {:.2f}!'.format(total_neurons, val_metric_name, bound_est, 100.0*neuron_gain, 100.0*min_neuron_gain))\n",
    "                        bound_didnt_improve = True\n",
    "                        break\n",
    "                    else:\n",
    "                        print('NETs Neuron Gain w/ {} neurons: {:.2f} >> {:.2f} = {:.2f}%'.format(total_neurons, metric_bound, bound_est ,100.0*neuron_gain))\n",
    "                else:\n",
    "                    print('Best Config Bound Estimation{:.2f}'.format(bound_est))\n",
    "            else:\n",
    "                print('No Bound Gain on {} neurons for {}: {:.2f} >> {:.2f}'.format(total_neurons, best_optimizer, metric_bound, bound_est))\n",
    "                bound_didnt_improve = True\n",
    "                break\n",
    "        elif my_mode == 'min':\n",
    "            if bound_est < metric_bound:\n",
    "                if metric_bound > 0.0:\n",
    "                    neuron_gain = 1.0 - bound_est/metric_bound\n",
    "                    if neuron_gain <= min_neuron_gain:\n",
    "                        print('NETs w {} neurons didnt improve {} {:.2f} neuron gain {:.2f} / min {:.2f}!'.format(total_neurons, val_metric_name, bound_est, 100.0*neuron_gain, 100.0*min_neuron_gain))\n",
    "                        bound_didnt_improve = True\n",
    "                        break\n",
    "                    else:\n",
    "                        print('NETs Neuron Gain w/ {} neurons: {:.2f} >> {:.2f} = {:.2f}%'.format(total_neurons, metric_bound, bound_est ,100.0*neuron_gain))\n",
    "                else:\n",
    "                    print('Best Config Bound Estimation{:.2f}'.format(bound_est))\n",
    "            else:\n",
    "                print('No Bound Gain on {} neurons for {}: {:.2f} >> {:.2f}'.format(total_neurons, best_optimizer, metric_bound, bound_est))\n",
    "                bound_didnt_improve = True\n",
    "                break\n",
    "\n",
    "    else:\n",
    "        print('BEST CONFIG {} & best quality for {}: {:.2f}'.format(best_config, best_optimizer.upper(), bound_est))\n",
    "    \n",
    "    metric_bound = bound_est\n",
    "\n",
    "    # ALTER CONFIG FROM BEST CONFIG IF NEEDED\n",
    "    if maximized_metrics or dont_need_extra_neurons or bound_didnt_improve:\n",
    "        still_searching = False\n",
    "    else:\n",
    "        current_configurations = best_config + search_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.12' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/higoreller/miniconda3/envs/condaenv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# ROLL BACK TO LESS NEURON IF DIDNT IMPROVE\n",
    "if bound_didnt_improve and rollback_on_no_bound_gain:\n",
    "    best_row = df_results[(df_results.neurons == best_config.sum() - 1) & df_results.is_best].tail(1)\n",
    "    best_net_name = best_row['model_name'].values[0]\n",
    "    best_optimizer = best_row['optimizer'].values[0]\n",
    "    best_net = best_row['net'].values[0]\n",
    "    best_config = best_row['net_config'].values[0]\n",
    "    best_features = best_row['features'].values[0]\n",
    "    best_neurons = best_row['neurons'].values[0]\n",
    "    best_metric = best_row[metric_name].values[0]\n",
    "    best_metric_val = best_row[val_metric_name].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.12' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/higoreller/miniconda3/envs/condaenv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# PREDICT\n",
    "ix_best_features = dfn['X'].columns.isin(best_features, level=1)\n",
    "Y_est_scaled = best_net.predict(X_scaled[:, ix_best_features], verbose=0)\n",
    "Y_est = Y_scaler.inverse_transform(Y_est_scaled)\n",
    "\n",
    "# PLOT Y Vs YEST\n",
    "df_result = pandas.DataFrame(index=df.index)\n",
    "df_result['Y'] = Y\n",
    "df_result['Y_est'] = Y_est\n",
    "df_result['r'] = df_result['Y_est'] - df_result['Y']\n",
    "df_result['rabs'] = df_result['r'].abs()\n",
    "df_result = df_result.join(df.loc[:, df.columns != reg_col])\n",
    "\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.12' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/higoreller/miniconda3/envs/condaenv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# STABLE RESIDUAL PLOT\n",
    "r_mean = df_result.r.median()\n",
    "r_std = df_result.r.std()\n",
    "r2 = r2_score(df_result.Y.to_numpy(), df_result.Y_est.to_numpy())\n",
    "\n",
    "fig = pyplot.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(121)\n",
    "lines = seaborn.scatterplot(data=df_result, x='Y', y='Y_est', size='rabs', ax=ax, label='residuo', color='green')\n",
    "_ = ax.plot([df_result.Y.min(), df_result.Y.max()], [df_result.Y.min(), df_result.Y.max()], color='green', label='ref')\n",
    "_ = ax.grid(alpha=0.2)\n",
    "_ = ax.set_title('{} R2: {:.1f}%'.format(best_net_name,100.0*r2), size=20)\n",
    "ax2 = ax.twinx()\n",
    "_ = seaborn.kdeplot(data=df_result, x='Y', ax=ax2, label='Y', color='green', fill=True, alpha=0.1, linewidth=0.7)\n",
    "_ = seaborn.kdeplot(data=df_result, x='Y_est', ax=ax2, label='Y_est', color='green', fill=True, alpha=0.5, linewidth=0.7)\n",
    "_ = ax2.set_ylabel('')\n",
    "_ = ax2.set_yticks([])\n",
    "_ = ax.legend(loc='upper right')\n",
    "_ = ax2.legend(loc='lower right')\n",
    "ax3 = fig.add_subplot(122)\n",
    "_ = seaborn.scatterplot(data=df_result, x='r', y='Y', ax=ax3, label='residuo', color='red')\n",
    "ax4 = ax3.twinx()\n",
    "_ = seaborn.kdeplot(data=df_result, x='r', ax=ax4, label='residuo', color='red', fill=True, alpha=0.5, linewidth=0.7)\n",
    "_ = ax4.grid(alpha=0.2)\n",
    "_ = ax4.set_ylabel('')\n",
    "_ = ax4.set_yticks([])\n",
    "_ = ax4.set_title('Residuo: {:.2f} +- {:.2f}'.format(r_mean, r_std), size=20)\n",
    "_ = ax3.plot([r_mean, r_mean], [df_result.Y_est.min(), df_result.Y_est.max()], '--', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.12' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/higoreller/miniconda3/envs/condaenv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_result.Y_est.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.12' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/higoreller/miniconda3/envs/condaenv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# SCATTER PLOT\n",
    "resplot_var = list(df.columns[df.columns != reg_col])\n",
    "resplot_var.append('r')\n",
    "g2 = seaborn.pairplot(df_result[resplot_var], hue='naturezas', height=3, diag_kind='kde')\n",
    "# _ = g2.map_lower(seaborn.kdeplot, levels=1, color=\".2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.12' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /home/higoreller/miniconda3/envs/condaenv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "81a3580d9119b5a6c386c26f975d9316f07a8b79ce368947d33d8f384f33fbaa"
   }
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "a71a1ad02e237783013e73aa0c06d9608f113229b1c33e91c79bde9fc7f65af1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
